Ten Lessons from a Year Building AI Agents in LegalTech
An AI engineer‚Äôs journey optimizing legal workflows with lessons learned from building, deploying, and maintaining intelligent agents.

Marcus K. Elwin
Marcus K. Elwin

Follow
22 min read
¬∑
May 18, 2025
710

10




Press enter or click to view image in full size

AI Agents x Legal tech, a match made in heaven? Source: imaged generated by author using gpt-image-1.
Table of Contents
Introduction
What is an Agent, and why does it matter for legal?
Examples of agentic use cases in legal tech
- Contract Review Agent
- Legal Research Agent
Ten lessons from working with Agents in LegalTech
- Lesson 1: Even if Agents are cool, they don‚Äôt solve all problems
- Lesson 2: Choose what framework solves your use case the best
- Lesson 3: Be able to iterate on different models quickly
- Lesson 4: Start simple, extend when necessary
- Lesson 5: Use a tracing solution; you will need it
- Lesson 6: Make sure to track costs, Agent loops can be expensive
- Lesson 7: Give control to the end-user (human-in-the-loop)
- Lesson 8: Always ground your Agent results
- Lesson 9: Prioritize ethical guardrails and explainability
- Lesson 10: Implement continuous monitoring and feedback
Conclusions
References
Introduction
When I started working in legal tech at the end of 2023, during the inception of the GenAI hype, legal professionals were beginning to understand the value of AI and applying it to their legal workflows. Many legal tech providers, like my employer, have added AI features to their platforms. These features used large language models in various non-agentic ways for the most part.
Then came 2024, with the boom of reasoning models, and people outside and within the industry started to understand that we were at a fundamental shift with agentic capabilities. For instance, a study by Clio (2024) showed that the AI adoption among legal professionals surged from ~19% to 79%, or ~415% increase [1].
We have seen similar adoption where I currently work. Now in 2025, the conversation is about agents and how we can build agentic systems in the best way possible. The legal domain presents unique opportunities for agentic systems. Legal work combines routine, document-heavy tasks with complex reasoning and strategic decision-making ‚Äî a perfect balance for AI augmentation.
In this post, I will share some lessons learned from building agentic systems from my point of view. The initial idea from this post came from a meetup I attended, where I presented the initial idea for these learnings. You can see the initial talk and repo here [2].
However, I will expand on these lessons in this post. We will start by discussing what an agent is, why it matters for legal, and examples of agentic use cases in legal tech. The ten lessons I‚Äôve observed. And finally ending with some conclusion for the future.
If you like this post, please add 50 claps üëè, comment or highlight relevant sections, and star my GitHub repo, which would be very appreciated.
Let‚Äôs get started, shall we üöÄ?
What is an Agent, and why does it matter for legal?
Press enter or click to view image in full size

Fig 1. Generative AI agent cycle. Source: Image by author using Napkin AI.
Like with many new technological advancements, whether new or old, there are many definitions for what an agent is or is not. Many of the big tech providers, such as Google [3], Langchain [4], Anthropic [5], and OpenAI [6], have their views on what an agent is and how to build it.
For instance, OpenAI [6] defines an agent as:
Agents are systems that independently accomplish tasks on your behalf.
OpenAI [6] also touches on the concept of agentic workflows:
A workflow is a sequence of steps that must be executed to meet the user‚Äôs goal, whether that‚Äôs resolving a customer service issue, booking a restaurant reservation, committing a code change, or generating a report.
Legal tech is a mix of agents or agentic workflows for various tasks, depending on the level of control required by the end-user, in this case, the legal professional. For instance, in legal tech, truly independent agents are not there yet. When we have AGI, this might change.
However, in its most fundamental form, a Generative AI agent can be defined as an application that attempts to achieve a goal by observing the world and acting upon it using the tools it has at its disposal (see figure 1 above).
Why do AI agents matter for Legal Work? Well, the legal profession faces some unique challenges that make it particularly well-suited for AI agents:
Document-heavy workflows: Legal professionals deal mainly with many different types of documents or contracts from various parties. They also produce quite a lot of text content in their work. Agents can process, analyze, and extract key clauses at scale.
Structured processing with complex reasoning: Many legal tasks follow predictable workflows (e.g., due diligence, contract review, or legal research). This requires deep reasoning and research to synthesize the correct information for a decision. This is a nice problem for an agentic system that can automate routine research while handling the complexity of reasoning.
Time-sensitive work billed by the hour: High-skilled professionals like lawyers aren‚Äôt cheap for clients and internal firms. Agents can be a way of cutting costs and letting the legal professional focus on high-value work instead.
Precision requirements: Errors in legal decisions can lead to severe consequences. Well-designed Agents, with human-in-the-loop mechanisms, are very important here.
Knowledge integration needs: Legal professionals must connect the dots between regulations, cases, and client-specific information. As mentioned, agents can be great for synthesising information from various sources and helping in decision-making.
I think (1) ‚Äî (6) above clearly indicate some of the legal challenges with AI and the opportunities one might have with building agents or agentic workflows to address these.
Examples of agentic use cases in legal tech
Before we dig into some of the lessons, it might be good to examplify a bit further some of the use cases where agentic capabilities can be helpful.
This is not an exhaustive list. Instead, we will focus on two widespread use case that most legal tech providers try to solve (1) Contract Review and (2) Legal Research.
Contract Review Agent
Press enter or click to view image in full size

Fig 2. Schematic representation of the Contract review process. Source: Image by author using Napkin AI.
Legal Contract Review examines a contract‚Äôs terms and conditions against legal or business guidelines. Usually, this is done using a policy document or playbook. See a schematic representation above in Figure 2.
To illustrate further, the process might look like the following:
User sends query: ‚ÄúPlease review this non-disclosure agreement (NDA)‚Äù
Agents understand that it deals with an NDA in a particular jurisdiction, say California. Based on the document content and playbook. Its goal is to find any potential legal gaps, ambiguities, typos, etc. This is its orchestration layer.
The agent might have access to previous interactions (short-term memory) or a more extended memory of company templates, for example.
The agent, via a Large Language Model or several, is used to reason around the clauses in the contract, compares these to the policy document or playbook, and plans the work.
As help, it may have one or several tools to do the contract analysis. For instance, a tool for finding risks is checking up various legal frameworks.
Agent responds with a list of recommendations after various iterations on finding what to present.
Now that we know some of the steps an agent of this type needs to take, let‚Äôs demonstrate an example on how to build this. We will use PydanticAI for this example. See full implementation in my repo here [2]. We will dicuss more around various frameworks in the lessons section.
Using PydanticAI we can specify an agent by using their Agent interface. In this example, we use OpenAI‚Äôs latest non-reasoning model.
from pydantic_ai import Agent

cr_agent = Agent(
    model='openai:gpt-4.1', 
    system=system_cr,
    human=human_cr,
    temperature=0.7, 
    verbose=True, 
    instrument=True
    )
In our example, we use the following prompt template:
def get_nda_analysis_prompt():
    """
    Returns a LangChain prompt template for analyzing NDA contracts against company policies.
    """
    system_message = """You are a legal analysis assistant specializing in Non-Disclosure Agreements (NDAs).
Your task is to analyze the provided NDA contract and determine if it complies with the company's NDA policy.

Follow these steps in your analysis:
1. Identify key clauses in the NDA (confidentiality obligations, term, exceptions, etc.)
2. Compare each clause against the company's NDA policy requirements
3. Flag any discrepancies or concerning provisions
4. Provide recommendations for negotiation or modification

Focus on the following key areas:
- Definition of Confidential Information
- Term of confidentiality obligations
- Permitted disclosures/exceptions
- Return/destruction of confidential information
- Governing law and jurisdiction
- Remedies for breach

Output your analysis in a structured format with clear recommendations.
"""

    human_message = """Please analyze this NDA contract against our company policy:

NDA Contract:
{contract_text}

Company NDA Policy:
{policy_text}
"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", human_message),
    ])
    
    return prompt
With the following templates:
{contract_text} the actual contract to analysis an example NDA.
{policy_text} the policy text or rules, found here.
‚ö†Ô∏è Note that the NDA and policy documents are AI-generated to showcase the example. This example contract review flow is simplified compared to how you would solve it in production, but you get the gist.
We continue with running the review:
review = cr_agent.run_sync(sample_nda)
Finally we get the AI review results:
Your **Mutual Non-Disclosure Agreement** is clear, comprehensive, and uses commonly accepted industry standards. Here are considerations, comments, and suggestions you might find helpful (from a lawyerly or business perspective):

---

### 1. **Substantive Review ‚Äì Highlights**

- **Mutual NDA**: The obligations and definitions apply to both parties, reflecting mutual intent.
- **Clear Purpose**: The "Purpose" is well-defined, which limits the scope of use.
- **Definition of Confidential Information**: Broad but clearly lists exclusions (good for clarity and to prevent disputes).
- **Data Privacy**: Inclusion of GDPR and CCPA compliance is current and relevant, especially with cross-jurisdictional issues.

---

### 2. **Areas to Double-Check**

#### **A. Execution/Signatures**
- **Signatures & Dates**: Only one party should typically insert the date beside their signature if all are signing on the same day, but this is not strictly necessary‚Äîjust ensure a fully executed copy is stored.
- Consider including **email addresses** under signatories for timely contact regarding breaches or notices.

#### **B. Notices**
- There is **no ‚ÄúNotice‚Äù clause** specifying how official communications, such as termination notices, must be delivered (email, mail, courier, etc.). Standard practice is to clarify this to avoid disputes.

    **Example:**  
    > Any notice required or permitted under this Agreement must be in writing and delivered in person, by courier, by certified mail (return receipt requested), or by email (with confirmation of receipt) to the address first listed above or such other address as either Party may specify in writing.

#### **C. Impact of Termination**
- The agreement provides that confidentiality obligations survive termination, but you may wish to clarify that **termination does not require return/destruction of Confidential Information** unless expressly requested by the disclosing party (as is now, but some agreements mandate this at the end automatically).

#### **D. Remedies**
- There is **no provision for injunctive relief** or acknowledgment that monetary damages may be insufficient for breach. Most NDAs state that a party may seek injunctive relief without posting a bond.

    **Example:**  
    > The Parties agree that a breach of this Agreement may cause irreparable harm for which monetary damages may be inadequate and, in the event of a breach, the disclosing party shall have the right to seek equitable relief, including injunction, in addition to any other remedies available at law.

#### **E. No Obligation to Proceed**
- Sometimes it‚Äôs helpful to clarify that **neither party is obligated to proceed with any transaction** as a result of the disclosure or discussions.

#### **F. Miscellaneous**
- **Counterparts & Electronic Signatures:** In the post-pandemic era, it's common to specify the agreement may be signed in counterparts (and/or electronically), each of which is binding.

    **Example:**  
    > This Agreement may be executed in counterparts and delivered electronically, each of which shall constitute an original, and all of which together shall constitute one instrument.

---

### 3. **Minor Typos/Stylistic Notes**

- In **Section 2.1**, consider ‚Äú‚Ä¶directly or indirectly, whether in writing, orally, or by inspection‚Ä¶‚Äù for fuller clarity. (Current is understandable.)
- The word "Non-Use" is not standard but is understandable contextually.
- Consistent use of ‚ÄúParty‚Äôs‚Äù vs. ‚ÄúParties‚Äô‚Äù (possessive)‚ÄîYours are correct.

---

### 4. **Legal Enforceability**

- **Governing Law & Jurisdiction**: Consistent with the principal business location; both parties may be amenable to California.
- **Term and Survival**: Three-year agreement term, with five-year confidentiality survival, is typical.

---

### 5. **Summary Recommendations**

- **Consider adding a Notice clause.**
- **Consider adding an Injunctive Relief clause.**
- **Optional**: Add counterparts/electronic signatures language.
- **Optional**: Add ‚ÄúNo Obligation to Proceed‚Äù language.

---

### 6. **Quick Sample Text: Injunctive Relief Clause**

REMEDIES Each Party agrees that any violation or threatened violation of this Agreement may cause irreparable injury to the disclosing Party, entitling the disclosing Party to seek injunctive relief in addition to all legal remedies.

---

If you need a redlined version with any of these changes, or have a specific clause you‚Äôd like reworded, let me know! Otherwise, as drafted, **your NDA should serve well for most standard purposes**.
Legal Research Agent
Press enter or click to view image in full size

Fig 3. Schematic representation of the Legal Research process. Source: Image by author using Napkin AI
Legal research has traditionally been a labor-intensive process requiring hours of meticulous work by attorneys and paralegals to find relevant precedents, analyze case law, and synthesize findings. This is also an ample process for using AI, see more in Figure 3. For now, we won‚Äôt go into too much detail for this process, maybe in a follow-up post.
Ten learnings from working with Agents in LegalTech
Press enter or click to view image in full size

Fig 4. Ten lessons from working with agents in legal tech. Source: Image by author.
Above, I‚Äôve gathered 10 key lessons from working with LLMs, AI agents, and agentic systems during my time in legal tech. Some of these might be more important for legal tech, but nonetheless, not unique to legal tech and relevant to other domains.
Lesson 1 ‚Äî Even if Agents are cool, they don‚Äôt solve all problems
Agents are all the rave at the moment. And rightfully show, there are many impressive agentic systems out there like Manus AI or Claude Code as examples. However, do you need to use agents for any AI-based problem?
Probably not, right? The first lesson comes from an observation I‚Äôve made when building LLM-powered AI systems:
Agents excel at orchestrating tasks but may not outperform specialized models, or stacked chains of LLM calls, or rule‚Äëbased systems for narrow jobs or tasks.
One common use case LLMs tend to work quite well for is metadata extraction. Using an Agent for this might be a bit overkill, but of course, it is completely possible. Let‚Äôs look at two examples, not using an Agent vs using an Agent.
The pydantic model we will be using to extract ContractMetadata:
class ContractMetadata(BaseModel):
      """Metadata extracted from a legal contract document"""

      parties: List[Party] = Field(
          description= "List of all parties involved in the contract"
      )

      notice_date: Optional[DateInfo] = Field(
          None,
          description="Date by which notice must be given"
      )

      termination_date: Optional[DateInfo] = Field(
          None,
          description="Date when the contract terminates"
      )

      contract_value: Optional[ContractValue] = Field(
          None,
          description="Monetary value of the contract"
      )

      personal_data: Optional[PersonalDataInfo] = Field(
          None,
          description="Information about personal data processing in the contract"
      )
Let‚Äôs start with the non-agentic path using an LLM chain. This is the prompt we will be using, and we define an extraction chain:
import json
from langchain_openai import ChatOpenAI

llm_openai = ChatOpenAI(
    model="gpt-4.1",
    temperature=0
)

structured_llm_openai = llm_openai.with_structured_output(ContractMetadata)

metadata_openai = chain_openai.invoke({
    "schema_str": json.dumps(ContractMetadata.model_json_schema(), indent=2),
    "contract_text": sample_nda, 
    "chat_history": []}
)
Using this chained approach, we obtain a fairly accurate extraction, which can be further refined with various prompt engineering techniques. If you want to see some tips, check one of my previous articles below:
Prompt Engineering Tips & Tricks for Named Entity Recognition (NER)
This article will cover some tips & tricks for doing Prompt Engineering for NER use cases. This is a summarized version‚Ä¶
blog.gopenai.com
However, using e.g., pydantic-ai, you can define the agent as below:
from pydantic_ai import Agent

openai_agent = Agent(
    model='openai:gpt-4.1', 
    system=system,
    human=human,
    temperature=0, 
    verbose=True, 
    output_type=ContractMetadata,
    instrument=True
    )
What you will notice when running both methods is that the agentic approach requires some tools to work more effectively than the chained approach. And potentially do more iterations, which is not wrong. However, it may not always be suitable for all problems.
Lesson 2‚Äî Choose what framework solves your use case the best
A lot has happened in the GenAI/LLM space over the last two years, and many smart people have been thinking about how to orchestrate and deploy LLM-powered applications. Which leads me to my second lesson:
Evaluate trade-offs in features, integrations, and community support before committing to one solution, or be quick at adapting to a different solution
There is a multitude of frameworks out there, such as:
Langraph/Langchain
Pydantic-AI
CrewAI
OpenAI Agents SKD
Mastra AI
Agent Development Kit
To mention a few but also a bunch of custom approaches built around DIY loops and orchestration with direct API calls. There has been quite a lot written around this in e.g. [4,5, 6], but how I like to reason around the frameworks vs custom solutions:

Table 1. Frameworks vs custom solutions Pro(s) and Con(s).
Choosing what framework to use seems to be an NP-complete problem, there is a lot of beef around it as well as of lately:

Tweet 1. Beef between PydanticAI, Langchain and ultimately OpenAI.
However, if I would put my bet on anything it would likely be Pydantic AI for python and Mastra AI for Typescript. Closely followed by the LLM providers own SDKs but let‚Äôs see what the future would hold. Langraph for instance is a solid framework with better abstractions then Langchain IMHO.
Lesson 3‚Äî Be able to iterate on different models quickly
Having AI as a feature is no longer any MOAT, rather a requirement but perhaps being able to quickly iterate on new models and having clever ways of combining different models with strenghts in various parts of an agentic flow might turn out to be some type of MOAT?
Which leads me to my third lesson:
Swap models in and out to optimize for cost, latency, and accuracy at each step of your agent pipeline
Of course you and your developer team don‚Äôt want to have to maintain different logic and ideally not different prompts for different models. Which is why an LLM proxy has become a quite popular addition and to todays LLMOps stack for companies. This is alos an essential layer and tool for agentic development workflows.
For prompt optimization, I can recommend to check DSPy, I did give it for a spin when it first was launched if you are interested below:
Using DSPy for extracting metadata NER style
DSPy, with its ‚Äúdeclarative‚Äù approach to instructing LLMs that favors programming over prompting, has quickly gained a‚Ä¶
blog.gopenai.com
Some LLM proxy alternatives (non exhaustive list) are for instance:
LiteLLM ‚Äî Open sourced python based library providing a unified interface for various models and providers
Portkey ‚Äî Enterprise LLM Gateway, Typescript based also have a lot around observability
OpperAI ‚Äî Functional framework with both proxy, tracing, evals and rag solution
Some of the benefits I‚Äôve seen by using this in our agent development:
Singel API to integrate with ‚úÖ
Simplified A/B testing of models ‚úÖ
Performance and cost tracking ‚úÖ
Fallback handling, load balancer etc for reliability ‚úÖ
Most of these proxy solutions follows OpenAI API pattern and with a base url switch you can get any OpenAI supported code work with e.g. another model or provider.
When you use a proxy solution and try various models for different agentic components, you can quite quickly get a feel for which models works best for various parts of the agentic flow.
Below are some of my observations:

Table 2. Strategic Model Selection for various parts of the agent flow.
Of course other reasoning models are also beneficial here.
Lesson 4‚Äî Start simple, extend when necessary
Less tends to be more sometimes. In my experience (although I know some legal tech providers do this) you don‚Äôt need a multi-agent system for most common legal tech tasks. Instead I tend to focus on having 5‚Äì10 or so adapt tools for the agent to use. Which leads me to my fourth lesson:
Begin with a minimal proof‚Äëof‚Äëconcept (one agent) and add complexity (many agents) only when you‚Äôve validated real user value.
However, below are some thoughts from my point of view when to use a Singel Agent vs a Multi-Agent approach:
Singel Agent:
Reviewing simple contracts ‚úÖ
Initial MVP or prototype ‚úÖ
Limited budget ‚úÖ
Quick turnaround is needed ‚úÖ
Simpler implementation requireiments ‚úÖ
Multi-Agent:
Complex contract analysis ‚úÖ
Need for detailed clause-by-clause review ‚úÖ
When different models works for certain parts of flow ‚úÖ
When transparency in the reasoning process is important ‚úÖ
When cost optimization across different steps matter ‚úÖ
Some of the multi-agent points hold true for a multi-leveled chain of LLM calls, but is that not a multi-agent approach you might ask? In my opinion very multi-leveled chains becomes hard to read, maintain and debug, where the multi-agent approach might be better.
To wrap-up we will show an example of a single vs multi-agent approach to contract review. For all details see the github repo in [2].
Continuing with using Pydantic AI a single agent would be defined:
from pydantic_ai import Agent

cr_agent = Agent(
    model='openai:gpt-4.1', 
    system=system_cr,
    human=human_cr,
    temperature=0.7, 
    verbose=True, 
    instrument=True
    )
And the prompt we will use is shown below:
def get_nda_analysis_prompt():
    """
    Returns a LangChain prompt template for analyzing NDA contracts against company policies.
    """
    system_message = """You are a legal analysis assistant specializing in Non-Disclosure Agreements (NDAs).
Your task is to analyze the provided NDA contract and determine if it complies with the company's NDA policy.

Follow these steps in your analysis:
1. Identify key clauses in the NDA (confidentiality obligations, term, exceptions, etc.)
2. Compare each clause against the company's NDA policy requirements
3. Flag any discrepancies or concerning provisions
4. Provide recommendations for negotiation or modification

Focus on the following key areas:
- Definition of Confidential Information
- Term of confidentiality obligations
- Permitted disclosures/exceptions
- Return/destruction of confidential information
- Governing law and jurisdiction
- Remedies for breach

Output your analysis in a structured format with clear recommendations.
"""

    human_message = """Please analyze this NDA contract against our company policy:

NDA Contract:
{contract_text}

Company NDA Policy:
{policy_text}
"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", human_message),
    ])
    
    return prompt
The example contract and playbook or policy for the review are found here.
Running the review using a single agent for the simple contract results in the following recommendations:
### 5. **Summary Recommendations**

- **Consider adding a Notice clause.**
- **Consider adding an Injunctive Relief clause.**
- **Optional**: Add counterparts/electronic signatures language.
- **Optional**: Add ‚ÄúNo Obligation to Proceed‚Äù language.
Which is probably good enough for the simple case. Let‚Äôs try a more complex contract and using the multi-agent approach:

Table 3. Example of a multi-agent system for Contract Review.
Above is one way of modelling the problem. Note that this is just an example and not a product ready version. We define the agents in this file.
First off we define the Extraction Agent :
extractor_agent = Agent(
    model='openai:gpt-4.1-mini',
    system="""You are a legal document analysis specialist focusing on contract clause extraction.
Your job is to identify and extract key clauses from Non-Disclosure Agreements (NDAs).

Extract clauses that are most legally significant, focusing on:
- Definition of Confidential Information
- Term and termination
- Obligations of confidentiality
- Permitted disclosures/exceptions
- Return/destruction of information
- Governing law and jurisdiction
- Remedies for breach
- Personal data protection

Be precise and thorough. Extract exact text and provide accurate section references.""",
    output_type=List[ClauseExtraction]
)
Secondly we define the Policy Agent :
policy_agent = Agent(
    model='openai:gpt-4.1',
    system="""You are a legal compliance specialist focusing on NDA policy alignment.
Your job is to compare contract clauses against a company's NDA policy to identify compliance issues.

For each clause, analyze:
1. How well it aligns with company policy (score 0-100)
2. Identify the specific policy section(s) it relates to
3. List specific issues or discrepancies
4. Determine if the clause is ultimately compliant

Be thorough in your analysis and focus on substantive legal issues.""",
    output_type=List[PolicyMatch]
)
Thirdly, we define the Suggestion Agent :
suggestion_agent = Agent(
    model='openai:gpt-4.1-mini',
    system="""You are a legal drafting specialist focusing on contract improvement.
Your job is to suggest improved language for contract clauses that don't align with company policy.

For each non-compliant clause:
1. Draft revised text that would make the clause compliant
2. Explain why this change is recommended
3. Rate the importance of making this change (1-10)

Write in clear, precise legal language. Focus on legally significant changes.""",
    output_type=List[ClauseSuggestion]
)
And finally, we define the Orchestrator Agent :
orchestrator = Agent(
    model='openai:gpt-4.1',
    system="""You are a legal contract review coordinator overseeing the review of an NDA.
You will:
1. Extract key clauses from the contract
2. Analyze each clause against company policy
3. Generate suggestions for improvement
4. Produce a final comprehensive review

Work systematically and ensure all important clauses are reviewed thoroughly.""",
    output_type=FinalReview,
    deps_type=ContractReviewDeps
)
Using Pydantic-AI each agent becomes a tool for the orchestrator to execute, based on user input. Again one could argue that you could use this as tools to a singel agent instead with various LLM chains.
Lesson 5‚Äî Use a tracing solution; you will need it
If machine learning models where blackbox before the GenAI hype, LLMs are now as blackbox as blackholes. This is why it is important to be able to trace each step of the LLM execution, see input and output to ease debugging. Which leads me to my fifth lesson:
Capture each prompt, tool call, and response to debug issues and maintain an audit trail.
This is probably what most companies start with in their LLMOps jurney and you have various solutions such as Langsmith, Langfuse etc to help you. Especially when agents or LLMs are not performing as expected these type of tools will be a life saver.
Pro tip to further increase the debugging capabilities:
Always ask the LLM to provide a reasoning or thought for why it is doing something, also before extracting any value to elicit Chain-of-Thought.
Lesson 6‚Äî Make sure to track costs, Agent loops can be expensive
The cost of reasoning and LLM models have steadly decreased. The cost of doing a simple call or a few steps of LLM calls are still more or less neglectable. What about the cost of a complex agent loop executing tools for a large number of iterations? Then we are talking about a few cents per call up to a few dollars per call. Not that neglectable any more.
Which leads me to my sixth lesson:
Monitor API usage and loop iterations to prevent unexpected billing spikes.
Combining this with an LLM proxy, you can easily track costs per client or end-user and identify potential bottlenecks you might have, get ideas for what type of pricing models to use or find caching opportunities.
What I have found helpful is do build data pipelines around this and expose metrics in e.g. internal dashboards for the entire business to know.
Lesson 7‚Äî Give control to the end-user (human-in-the-loop)
This goes without saying but for professional services such as legal, trust is paramount. This holds true for other domains as well. And one way of giving or improving trust is to have human-in-the-loop mechanisms.
Which leads me to my seventh lesson:
Allow humans to intervene, review, and override agent decisions at critical steps.
Some guiding principles I have seen here:
Propose instead of imposing a solution or change
Highlight uncertainties where human judgement is needed
Allow the end-user to override or adjust the agents recommendations
Provide explanation in the interface to allow the end-user to understand the agents reasoning.
See an example below of our Word-plugin and Review feature I was part of building incorporating some of these principles:
Press enter or click to view image in full size

Fig 5. Example of contract review in word with some HIL principles. Source: Image by author.
Lesson 8‚Äî Always ground your Agent results
Slightly connected to the previous lesson, on the topic of trust. LLM are non-deterministic or stochastic. This stochasticity multiplies with the more LLM calls one is doing i.e. in an agent flow.
Which leads me to my eight lesson:
Provide source snippets and citations so end-users can verify and trust AI outputs.
In the legal context it is important that agent who makes legal asserstions ore suggestion:
Reference specific policy sections, statues or precedents
Qoute the exact language that supports its conclusions
Differentiate between established law and probabilistic reasoning
Acknowledge jurisprudential uncertainty where it exists
Below are some grounding methods I‚Äôve found usefully:

Table 4. Example of different grounding methods used for AI.
Lesson 9‚Äî Prioritize ethical guardrails and explainability
Legal AI applications face unique ethical and regulatory challenges, such as (1) unauthorized practice of law concerns, (2), confidentiality and privilege preservation, (3) bias mitigation, especially in areas like litigation prediction and (4) GDPR and other data protection regulations.
Of course other domains, have similar challenges, but for legal in its inherent legal nature this is often very important. Which leads me to my ninth lesson:
Build in audit logs, human‚Äëescalation triggers and clear rationales so every decision is transparent and GDPR‚Äë/industry‚Äëready.
Some guardrails one could use here are:
Clear disclaimers about the agent‚Äôs role and limitations
Logging of data access and processing for compliance certification
Deliberate limitations on conclusory legal opinions (i.e. only give a suggestion)
Review processes for potential biased outputs.
Lesson 10 ‚Äî Implement continuous monitoring and feedback
Like in the old machine learning world, model drift, feature drift and data drift can have serious implications on the performance of your machine learning system.
Same of course holds true for GenAI, even if you don‚Äôt own the models you own your context, and prompts which might also be subject to potential drift.
Which leads me to my tenth and final lesson:
Define clear KPIs (accuracy, cost, user satisfaction), collect metrics from each run, and regularly refine prompts, tools, and models with your legal team.
Legal language and requirements evolve constantly with new regulations, precedents and industry practices.
Make sure to:
Gather structured feedback from end-users on agent performance
Monitor for changes in relevant regulations and update knowledge bases such as prompts
Track instances where suggestions were rejected and gather info for why
Periodically audit agent outputs against evolving legal standards.
Conclusions
Agents have been the main LLM and AI adoption topics for the past few months. And there have been many guides written around them. I‚Äôve been missing more insights and input from practitioners in various domains. In this article, I attempt to distill what I‚Äôve seen into 10 lessons from building agents in legal tech.
To summarize what has been said, I think there are five key takeaways:
Match Technology to the Task: Not every legal task requires a complex agent system. Identify where simple, direct LLM calls are sufficient versus where an orchestrated multi-agent system adds more value. Using a more straightforward approach, where appropriate, will reduce complexity, cost, and potential failures.
Build for Verification: Legal professionals will fact-check AI output by training and professional pedigree. Design systems that ground assertions in source documents, provide citations and explain reasoning and agent thinking transparently. This helps build trust and convert AI from a ‚Äúblack box‚Äù to lawyers who must be verified to a trusted partner, accelerating their verification process.
Maintain Human Control: The most successful legal AI system preserves attorney agency and decision-making authority. Human-in-the-loop design that positions AI as enhancing rather than replacing legal expertise achieves higher adoption rates and mitigates faulty decision-making and bad practices. Most end-users, whether lawyers or others, want to be amplified or augmented when using AI and not replaced.
Optimize Performance & Costs: Be strategic in using model capabilities for different tasks to maximize efficiency. Use smaller, faster models, e.g., extraction and classification tasks, while preserving powerful (but more expensive) models for complex reasoning and analysis. This approach balances costs, performance, and accuracy for your AI applications.
Continuous Improvements: Legal AI or any other AI system in some domain are never ‚Äúdone‚Äù. Input to the system, the models, and users both change and evolve. Therefore, implement robust monitoring, tracing, and feedback systems to track performance, identify improvement, and adapt to the evolving requirements of your AI system. This ongoing refinement cycle will guarantee that your agents remain accurate, relevant, and valuable.
References
How Large Language Models (LLMs) Are Revolutionizing the Legal Industry,‚Äù Ioni AI, 2024, https://ioni.ai/post/how-large-language-models-llms-are-revolutionizing-the-legal-industry
Marcus Elwin, ‚ÄúAI Engineering Stockholm: Learnings from building AI agents in legal tech,‚Äù GitHub, 2024, https://github.com/MarcusElwin/ai-eng-sto-learnings-legal-agents
What are AI agents? Definition, examples, and types,‚Äù Google Cloud, 2024, https://cloud.google.com/discover/what-are-ai-agents
What is an AI agent?‚Äù LangChain Blog, November 13, 2024, https://blog.langchain.dev/what-is-an-agent/
Building Effective AI Agents,‚Äù Anthropic, 2024, https://www.anthropic.com/engineering/building-effective-agents
A Practical Guide to Building Agents,‚Äù OpenAI, 2025, https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf